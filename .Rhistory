a<- Test(i)
print(a)
}
View(df)
Tdata <- read.table(header=TRUE, text='
id weight
1     20
2     27
3     24
')
Tdata''
Tdata
View(Tdata)
Tdata$drugName <-2
View(df)
input <- read.csv(file ="inputTableFinal.csv",sep = ",",stringsAsFactors=FALSE)
pos.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/positive-words.txt', what='character', comment.char=';') #folder with positive dictionary
neg.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/negative-words.txt', what='character', comment.char=';') #folder with negative dictionary
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=3200, lang = "en")
df <- twListToDF(list)
return(df)
}
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
b<- data.frame(a$text,a$favoriteCount,a$created,a$id,a$retweetCount)
b$drugName <- input$drugName[i]
stack <- df
stack <- rbind(stack, df)
}
View(stack)
list <- searchTwitter("levocetirizine",  n=100, lang = "en")
list <- searchTwitter("doxylamine",  n=100, lang = "en")
list <- searchTwitter(" triprolidine",  n=100, lang = "en")
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=3200, lang = "en")
if(length(list) == 0) {
return()
}
df <- twListToDF(list)
return(df)
}
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library(wordcloud)
library(SnowballC)
library(tm)
library(RCurl)
library(purrr)
library(dplyr)
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library(wordcloud)
library(SnowballC)
library(tm)
library(RCurl)
library(purrr)
library(dplyr)
require("ROAuth")
require("RCurl")
t_consumer_key<-	'JALgcUhEQKGP3N1JXcg5oxJ4O'
t_consumer_secret<- 'GGqQsh0mHNNLqVKu9DF0rQs6PmFfEwwOCzJLZKHnlH5lLNoZSh'
t_access_token<-	'958495952041627649-63gHmzaZRdBnQM6p2UhRlKVNZcFd1pP'
t_access_secret <-	'rUbpZgVGj8gF5Uz6uN6GnWWb88JcRzxi2nXJ7OWCbQ36i'
setup_twitter_oauth(t_consumer_key,t_consumer_secret,t_access_token,t_access_secret)
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=3200, lang = "en")
if(length(list) == 0) {
return()
}
df <- twListToDF(list)
return(df)
}
input <- read.csv(file ="inputTableFinal.csv",sep = ",",stringsAsFactors=FALSE)
pos.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/positive-words.txt', what='character', comment.char=';') #folder with positive dictionary
neg.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/negative-words.txt', what='character', comment.char=';') #folder with negative dictionary
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
if (nrow(a)==0) {
next
}
b<- data.frame(a$text,a$favoriteCount,a$created,a$id,a$retweetCount)
b$drugName <- input$drugName[i]
stack <- b
stack <- rbind(stack, b)
}
View(stack)
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
b<- data.frame(a$text,a$favoriteCount,a$created,a$id,a$retweetCount)
b$drugName <- input$drugName[i]
stack <- b
stack <- rbind(stack, b)
}
View(stack)
stack <-data.frame()
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
stack <- rbind(stack, b)
}
list <- searchTwitter("triprolidine",  n=100, lang = "en")
list <- searchTwitter("Pyril D",  n=100, lang = "en")
list <- searchTwitter("Benadryl",  n=100, lang = "en")
list <- searchTwitter("Vicks DayQuil Severe Cold & Flu",  n=100, lang = "en")
list <- searchTwitter("Vicks DayQuil",  n=100, lang = "en")
list <- searchTwitter("Benadryl Allergy Plus Cold",  n=100, lang = "en")
list <- searchTwitter("Benadryl Allergy",  n=100, lang = "en")
list <- searchTwitter("Benadryl Allergy",  n=100, lang = "en")
list <- searchTwitter("	Vicks NyQuil",  n=100, lang = "en")
list <- searchTwitter("Tylenol Cold",  n=100, lang = "en")
list <- searchTwitter("Tylenol Cold",  n=100, lang = "en")
list <- searchTwitter("Coricidin HBP Cold & Flu",  n=100, lang = "en")
list <- searchTwitter("Coricidin HBP",  n=100, lang = "en")
list <- searchTwitter("Coricidin",  n=100, lang = "en")
list <- searchTwitter("Promethazine DM",  n=100, lang = "en")
list <- searchTwitter("Promethazine",  n=100, lang = "en")
input <- read.csv(file ="inputTableFinal.csv",sep = ",",stringsAsFactors=FALSE)
df <- twListToDF(list)
colnames(df)
colnames(df)
r<-data.frame(colnames(df))
View(r)
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=3200, lang = "en")
if(length(list) == 0) {
return()
}
df <- twListToDF(list)
return(df)
}
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
stack <- rbind(stack, b)
}
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=100, lang = "en")
if(length(list) == 0) {
return()
}
df <- twListToDF(list)
return(df)
}
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
datalist[[i]] <- a
}
datalist = list()
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
datalist[[i]] <-a
}
View(datalist)
big_data = do.call(rbind, datalist)
View(big_data)
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
a$drugName <- input$drugName[i]
datalist[[i]] <-a
}
big_data = do.call(rbind, datalist)
View(big_data)
#To remove duplicates
big_data <- subset(big_data, !duplicated(big_data$text))
b<- data.frame(a$text,a$favoriteCount,a$created,a$id,a$retweetCount)
View(b)
as <- data.frame( a = 1:10, b = 2:11, c = 3:12 )
View(as)
asd <- subset(df, select = c(a,c))
asd <- subset(df, select = c(a,c))
asd <- subset(df, select = -c(a,c))
as <- subset(df, select = -c(a,c))
asd <- data.table(as)
?data.table
??data.table
dfnew4 <- diamonds[,c(a,b)]
dfnew4 <- as[,c(a,b)]
dfnew4 <- data.frame(c(as$a,as$b))
View(dfnew4)
dfnew4 <- data.frame(,c(as$a,as$b))
colnames(big_data)
T1   <-big_data[ , which(names(big_data) %in% c("favoriteCount","created","id","retweetCount"))]
View(T1)
T1   <-big_data[ , which(names(big_data) %in% c("favoriteCount","created","id","retweetCount","text","drugName"))]
View(T1)
final_data<- big_data[ , which(names(big_data) %in% c("favoriteCount","created","id","retweetCount","text","drugName"))]
df <- final_data[, order(names(final_data))]
df$created <- strftime(df$created, '%Y-%m-%d')
View(df)
TwitterCollectionFunc<- function(searchterm){
list <- searchTwitter(searchterm,  n=100, lang = "en")
if(length(list) == 0) {
return()
}
df <- twListToDF(list)
return(df)
}
input <- read.csv(file ="inputTableFinal.csv",sep = ",",stringsAsFactors=FALSE)
pos.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/positive-words.txt',
what='character', comment.char=';') #folder with positive dictionary
neg.words <- scan('C:/Users/monis/Pictures/Capstone Project R/druganalysisLocal/negative-words.txt',
what='character', comment.char=';') #folder with negative dictionary
TwitterDataCleaningFunc<- function(){
datalist = list()
for (i in 1:nrow(input)) {
a<- TwitterCollectionFunc(input$drugName[i])
a$drugName <- input$drugName[i]
datalist[[i]] <-a
}
#To combine all
big_data = do.call(rbind, datalist)
#To remove duplicates
big_data <- subset(big_data, !duplicated(big_data$text))
final_data<- big_data[ , which(names(big_data) %in% c("favoriteCount","created","id",
"retweetCount","text","drugName"))]
df <- final_data[, order(names(final_data))]
df$created <- strftime(df$created, '%Y-%m-%d')
return(df)
}
w<- TwitterDataCleaningFunc()
View(w)
TwitterScoreFunction <-function(){
output1 <- TwitterDataCleaningFunc()
outputWithScores <- score.sentiment(output1$text, pos.words, neg.words, .progress='text')
return(outputWithScores)
}
score.sentiment = function(sentences , pos.words, neg.words , .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences,function(sentence,pos.words,neg.words)
{
sentence =gsub('[[:punct:]]','',sentence)
sentence =gsub('[[:cntrl:]]','',sentence)
sentence =gsub('\\d+','',sentence)
sentence=tolower(sentence)
word.list=str_split(sentence,'\\s+')
words=unlist(word.list)
pos.matches=match(words,pos.words)
neg.matches=match(words,neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score=sum(pos.matches)-sum(neg.matches)
return(score)
},pos.words,neg.words,.progress=.progress)
scores.df=data.frame(scores=scores,text=sentences)
return(scores.df)
}
score.sentiment = function(sentences , pos.words, neg.words , .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences,function(sentence,pos.words,neg.words)
{
sentence =gsub('[[:punct:]]','',sentence)
sentence =gsub('[[:cntrl:]]','',sentence)
sentence =gsub('\\d+','',sentence)
sentence=tolower(sentence)
word.list=str_split(sentence,'\\s+')
words=unlist(word.list)
pos.matches=match(words,pos.words)
neg.matches=match(words,neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score=sum(pos.matches)-sum(neg.matches)
return(score)
},pos.words,neg.words,.progress=.progress)
scores.df=data.frame(scores=scores)
return(scores.df)
}
t1<-data.frame(a=1:3, b=4:6)
t2 <- data.frame(c=-2:0, d=3:1)
View(t1)
View(t2)
t <- cbind(t1,t2)
View(t)
w<- TwitterScoreFunction()
score.sentiment = function(sentences , pos.words, neg.words , .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences,function(sentence,pos.words,neg.words)
{
sentence =gsub('[[:punct:]]','',sentence)
sentence =gsub('[[:cntrl:]]','',sentence)
sentence =gsub('\\d+','',sentence)
sentence=str_replace_all(sentence,"[^[:graph:]]", " ")
sentence=tolower(sentence)
word.list=str_split(sentence,'\\s+')
words=unlist(word.list)
pos.matches=match(words,pos.words)
neg.matches=match(words,neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score=sum(pos.matches)-sum(neg.matches)
return(score)
},pos.words,neg.words,.progress=.progress)
scores.df=data.frame(scores=scores)
return(scores.df)
}
w<- TwitterScoreFunction()
View(w)
output1 <- TwitterDataCleaningFunc()
outputWithScores <- score.sentiment(output1$text, pos.words, neg.words, .progress='text')
finalOutput <- cbind(output1,outputWithScores)
TwitterScoreFunction <-function(){
output1 <- TwitterDataCleaningFunc()
outputWithScores <- score.sentiment(output1$text, pos.words, neg.words, .progress='text')
finalOutput <- cbind(output1,outputWithScores)
return(finalOutput)
}
w<-TwitterScoreFunction()
View(w)
View(w)
stack <- w
View(w)
View(w)
write.csv(w, file = "MyDataStack.csv")
library(sentiment)
install.packages(sentiment)
install.packages(Rsentiment)
install.packages('RSentiment')
library(RSentiment)
library(RSentiment)
calculate_total_presence_sentiment(c("This is good","This is bad"))
calculate_sentiment(c("This is good","This is bad"))
calculate_sentiment(c("This is very very good","This is bad"))
calculate_sentiment(c("I like this food too much.","This is bad"))
w$sentimentResult <- calculate_sentiment(w$text)
View(w)
sentimentResult <- calculate_sentiment(w$text)
sent <- calculate_total_presence_sentiment(w$text)
sent <- calculate_total_presence_sentiment(w$text)
install.packages('rJava')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_161')
library(rJava)
library(rJava)
library(rJava)
??R.version
R.version
library(rJava)
library(rJava)
install.packages('rJava')
library(rJava)
sentimentResult <- calculate_sentiment(w$text)
library(RSentiment)
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library(wordcloud)
library(SnowballC)
library(tm)
library(RCurl)
library(purrr)
library(dplyr)
library(RSentiment)
library(RColorBrewer)
library(wordcloud)
library(tm)
library(twitteR)
library(ROAuth)
library(plyr)
library(stringr)
library(base64enc)
library(wordcloud)
library(SnowballC)
library(tm)
library(RCurl)
library(purrr)
library(dplyr)
sentimentResult <- calculate_sentiment(w$text)
score.sentiment = function(sentences , pos.words, neg.words , .progress='none')
{
require(plyr)
require(stringr)
scores = laply(sentences,function(sentence,pos.words,neg.words)
{
sentence =gsub('[[:punct:]]','',sentence)
sentence =gsub('[[:cntrl:]]','',sentence)
sentence =gsub('\\d+','',sentence)
sentence =gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", sentence)
sentence=str_replace_all(sentence,"[^[:graph:]]", " ")
sentence=tolower(sentence)
word.list=str_split(sentence,'\\s+')
words=unlist(word.list)
pos.matches=match(words,pos.words)
neg.matches=match(words,neg.words)
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
score=sum(pos.matches)-sum(neg.matches)
return(score)
},pos.words,neg.words,.progress=.progress)
scores.df=data.frame(scores=scores)
return(scores.df)
}
w1<- TwitterDataCleaningFunc()
require("ROAuth")
require("RCurl")
t_consumer_key<-	'JALgcUhEQKGP3N1JXcg5oxJ4O'
t_consumer_secret<- 'GGqQsh0mHNNLqVKu9DF0rQs6PmFfEwwOCzJLZKHnlH5lLNoZSh'
t_access_token<-	'958495952041627649-63gHmzaZRdBnQM6p2UhRlKVNZcFd1pP'
t_access_secret <-	'rUbpZgVGj8gF5Uz6uN6GnWWb88JcRzxi2nXJ7OWCbQ36i'
setup_twitter_oauth(t_consumer_key,t_consumer_secret,t_access_token,t_access_secret)
w1<- TwitterDataCleaningFunc()
View(w1)
w1<- TwitterScoreFunction()
View(w1)
sent <- calculate_total_presence_sentiment(w1$text)
library(rJava)
R.version
library(rJava)
library(rJava)
sent <- calculate_total_presence_sentiment(w1$text)
View(sent)
sentimentResult <- calculate_sentiment(w1$text)
View(sentimentResult)
w$sentiment <- calculate_sentiment(w$text)
View(w)
View(w)
w <- TwitterScoreFunction()
sentiment <- calculate_sentiment(w$text)
Output <- cbind(w,sentiment)
View(Output)
View(sentiment)
Output <- cbind(w,sentiment$sentiment)
View(Output)
s1<-sentiment$sentiment
s1<-data.frame()
s1<- sentiment$sentiment
senti <- calculate_sentiment(w$text)
s1<-data.frame()
s1<- senti$sentiment
Output <- cbind(w,s1)
sentimentOfText<- senti$sentiment
Output <- cbind(w,sentimentOfText)
View(Output)
View(Output)
dfrm <- Output
dfrm$normFavCount <- NA
View(dfrm)
nrow(dfrm)
min(dfrm$retweetCount)
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm, (retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
round(normFavCount, digits=4)
round(dfrm$normFavCount, digits=4)
dfrm$normFavCount<- round(dfrm$normFavCount, digits=4)
dfrm <- Output
dfrm$normFavCount <- NA
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
dfrm$normFavCount<- round(dfrm$normFavCount, digits=8)
dfrm$normFavCount <- NA
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
class(dfrm)
class(dfrm$normFavCount)
dfrm$normFavCount<- round(dfrm$normFavCount, digits=3)
dfrm <- Output
dfrm$normFavCount <- NA
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
View(dfrm)
dfrm$normFavCount<- as.integer(dfrm$normFavCount)
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
dfrm$normFavCount<- as.integer(dfrm$normFavCount)
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
dfrm$normFavCount<- as.float(dfrm$normFavCount)
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
dfrm$normFavCount<- as.double(dfrm$normFavCount)
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
dfrm <- Output
dfrm$normFavCount <- NA
dfrm$normFavCount <- dfrm$favoriteCount
normalize(dfrm$normFavCount , method = "standardize", range = c(0, 1), margin = 1L, on.constant = "quiet")
dfrm$normFavCount[1]*2
dfrm$normFavCount[3]*2
dfrm$normFavCount[1:nrow(dfrm)] <- with(dfrm,
((retweetCount[1:nrow(dfrm)]-min(dfrm$retweetCount))/max(dfrm$retweetCount))*2
)
